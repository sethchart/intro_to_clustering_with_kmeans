{"cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Introduction to Clustering: $k$-means"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### By the end of this lecture, students will have:\n", "\n", "- **Assessed** what scenarios could use $k$-means\n", "\n", "- **Articulated** the methodology used by $k$-means\n", "\n", "- **Applied** KMeans from sklearn.cluster to a relevant dataset\n", "\n", "- **Selected** the appropriate number of clusters using $k$-means and the elbow method\n", "\n", "- **Practiced** applying kmeans to an image color reduction problem\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Scenario\n", "\n", ">You work for the marketing department within a large company that manages a customer base. \n", "For each customer you have a record of average purchase cost and time since last purchase.<br> \n", "You know that if you want to retain your customers you cannot treat them the same. You can use targeted marketing ads towards groups that demonstrate different behavior, but how will you divide the customers into groups?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## **Part 1**: Concept introduction\n", "#### Import libraries and download dataset\n", "\n", "We are continuing to use Scikit Learn as our main library.\n", "The specific documentation for k-means can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import sys\n", "module_path = os.path.abspath(os.pardir)\n", "if module_path not in sys.path:\n", "    sys.path.append(module_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# Required packages for today\n", "from sklearn.cluster import KMeans\n", "from sklearn import metrics\n", "from sklearn import datasets\n", "\n", "# Familiar packages for plotting, data manipulation, and numeric functions\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import numpy as np\n", "\n", "# import Alison's code for the demo clusters\n", "from src.demo_images import *\n", "\n", "# Have plots appear in notebook\n", "%matplotlib inline\n", "\n", "# Default plot params\n", "plt.style.use('seaborn')\n", "cmap = 'tab10'"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Clustering!   Finding **GROUPS**\n", "\n", "How many groups do you see?\n", "\n", "![img](../img/initialscenario.png)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Wait - How is clustering different from classification?\n", "\n", ">In _classification_ you **know** what groups are in the dataset and the goal is to _**predict**_ class membership accurately.\n", "\n", ">In _clustering_ you **do not** know which groups are in the dataset and you are trying to _**identify**_ the groups."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### So what do you do with clustering results?\n", "\n", "Clustering is often an *informing* step in your analysis. Once clusters are identified, one can:\n", "- Create strategies on how to approach each group differently\n", "- Use cluster membership as an independent variable in a predictive model\n", "- Use the clusters as the _**target label**_ in future classification models. How would you assign new data to the existing clusters?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Explore the algorithm with an intuitive K means approach\n", "\n", "### Observe the following four methods with a sample dataset:\n", "\n", "### Method Questions:\n", "\n", "- What do they have in common?\n", "- What are the differences between them?\n", "- How many groups are there in the end?\n", "- Do you see any problems with this method?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Method 1\n", "\n", "![left](../img/from-left.gif)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Method 2\n", "\n", "![right](../img/from-right.gif)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Method 3\n", "\n", "![top](../img/from-top.gif)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Method 4\n", "\n", "![bottom](../img/from-bottom.gif)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Review Method Questions:\n", "\n", "- What do they have in common?\n", "- What are the differences between them?\n", "- How many groups are there in the end?\n", "- Do you see any problems with this method?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "notes"}}, "source": ["In common:\n", "- Green dots starts at points\n", "- Calculates distance\n", "- Moves dots\n", "- Re-measures distance\n", "- Moves dots as needed\n", "\n", "\n", "Differences:\n", "- Dots start in different places and groups settle in different places\n", "\n", "Groups:\n", "- There are four groups\n", "\n", "Problem with this method?\n", "- Too variable!"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### K-means algorithm, at its core, in an optimization function\n", "\n", "![minmax](../img/minmaxdata.png)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Reassigns groups and adjusts centroids to...\n", "![min](../img/min.png)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### And to...\n", "![max](../img/max.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The steps of the KMeans algorithm are pretty straightforward:\n", "  1. Initialize cluster centers.\n", "  2. Calculate the distance of every point to in the data set to each cluster center, and assign each point to the closest center.\n", "  3. Make new cluster centers assigned to the averge of a all points labeled to the cluster.\n", "  4. Repeat until some criteria has been met (the clusters no longer move)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["**Sci-kit Learn** documentation actually has some pretty good [documentation describing the algorithm](https://scikit-learn.org/stable/modules/clustering.html#k-mean) if you wish for more detail."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Data for the exercise\n", "\n", "- This is a sample dataset. \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.cluster import KMeans"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dummy_dat = pd.read_csv(\"data/xclara.txt\",\n", "                        header=0,\n", "                        index_col=0)\n", "dummy_dat.reset_index(inplace=True)\n", "dummy_dat.drop('index', axis=1, inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dummy_dat.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dummy_dat.tail()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### EDA of variables"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dummy_dat.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.scatter(dummy_dat['V1'], dummy_dat['V2']);"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### Introduction of `KMeans` class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# fit a KMeans Model on the dummy data. Initialize with n_clusters = 3\n", "model = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice the `init` and `n_init` parameters!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Inspect the cluster centers attribute"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.scatter(dummy_dat['V1'], dummy_dat['V2'])\n", "for i in range(len(model.cluster_centers_)):\n", "    ax.scatter(model.cluster_centers_[i][0],\n", "                model.cluster_centers_[i][1]);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use the predict method on a list of 2 x and y values\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.scatter(dummy_dat['V1'], dummy_dat['V2'],\n", "           c='#f30303');"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots()\n", "ax.scatter(dummy_dat['V1'], dummy_dat['V2'],\n", "           c= model.labels_);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["labeled_df = pd.concat([dummy_dat, pd.DataFrame(model.labels_,\n", "                        columns=['cluster'])], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["labeled_df.head()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## **Part 2**: Cluster Validation: Choosing the appropriate number of $k$\n", "\n", "#### Two metrics we can use: **elbow method** and the **silhouette coefficient**"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### **Part 2A**: Elbow Method\n", "\n", "Elbow method uses the sum of squared error calculated from each instance of $k$ to find the best value of $k$.\n", "\n", "This is sometimes called the \"inertia\" of the model, and fitted sklearn $k$-means models have an `inertia_` attribute.\n", "\n", "Fewer clusters seems better, but inertia will always decrease with _more_ clusters. Hence the idea of looking for an elbow in the plot of inertia vs. $k$."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.inertia_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Inertia is the sum of squared distances between points and their cluster center."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Specifying the dataset and initializing variables\n", "X = dummy_dat\n", "distortions = []\n", "\n", "# Calculate SSE for different K\n", "for k in range(2, 10):\n", "    kmeans = KMeans(n_clusters=k, random_state=301)\n", "    kmeans.fit(X)\n", "    distortions.append(kmeans.inertia_)\n", "\n", "# Plot values of SSE\n", "fig, ax = plt.subplots(figsize=(10, 8))\n", "ax.set_title('Elbow curve')\n", "ax.set_xlabel('k')\n", "ax.plot(range(2, 10), distortions)\n", "ax.grid(True)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### **Part 2B**: Silhouette Coefficient\n", "\n", "![silo](../img/silo2.png)\n", "\n", "> **a** refers to the average distance between a point and all other points in that cluster.\n", "\n", "> **b** refers to the average distance between that same point and all other points in clusters to which it does not belong\n", "\n", "It is calculated for each point in the dataset, then averaged across all points for one cumulative score.\n", "\n", "The Silhouette Coefficient ranges between -1 and 1. The closer to 1, the more clearly defined are the clusters. The closer to -1, the more incorrect assignment.\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Suppose:\n", "- I have four points in a one-dimensional space: 0, 1, 9, and 10; and\n", "- I put them into two clusters: {0, 1} and {9, 10}.\n", "\n", "Then we would calculate the Silhouette Score as follows:\n", "\n", "For Point 0:\n", "- $a=1$\n", "- $b=9.5$\n", "- $s(0) = \\frac{9.5 - 1}{9.5} = \\frac{17}{19}$\n", "\n", "For Point 1:\n", "- $a=1$\n", "- $b=8.5$\n", "- $s(1) = \\frac{8.5 - 1}{8.5} = \\frac{15}{17}$\n", "\n", "For Point 9:\n", "- $a=1$\n", "- $b=8.5$\n", "- $s(9) = \\frac{8.5 - 1}{8.5} = \\frac{15}{17}$\n", "\n", "For Point 10:\n", "- $a=1$\n", "- $b=9.5$\n", "- $s(10) = \\frac{9.5 - 1}{9.5} = \\frac{17}{19}$\n", "\n", "The full Silhouette Score would be the average of all of these individual scores:\n", "\n", "$\\large s = \\frac{2\\left(\\frac{17}{19}\\right) + 2\\left(\\frac{15}{17}\\right)}{4}$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "skip"}}, "outputs": [], "source": ["# Generate silhouette coefficient for each k\n", "X = dummy_dat\n", "silhouette_plot = []\n", "for k in range(2, 10):\n", "    clusters = KMeans(n_clusters=k, random_state=10)\n", "    cluster_labels = clusters.fit_predict(X)\n", "    silhouette_avg = metrics.silhouette_score(X, cluster_labels)\n", "    silhouette_plot.append(silhouette_avg)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Plot Silhouette coefficient\n", "fig, ax = plt.subplots(figsize=(10, 8))\n", "ax.set_title('Silhouette coefficients over k')\n", "ax.set_xlabel('k')\n", "ax.set_ylabel('silhouette coefficient')\n", "ax.plot(range(2, 10), silhouette_plot)\n", "ax.axhline(y=np.mean(silhouette_plot), color=\"red\", linestyle=\"--\")\n", "ax.grid(True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Activity"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's practice k-means clustering with an image of a piece of art. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Our new clustering class\n", "from sklearn.cluster import KMeans\n", "\n", "import matplotlib.pyplot as plt\n", "# Allows us to visualize images through matplotlib plot methods\n", "import matplotlib.image as mpimg\n", "\n", "# Old favorites\n", "import pandas as pd\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's look at a colorful Miro painting with matplotlib."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10,10))\n", "img = mpimg.imread('data/miro.jpg')\n", "imgplot = ax.imshow(img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# What is the shape of the image, and what does each component represent?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Code here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Let's look at one pixel\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Flatten the image so that each row represents one RGB triad\n", "img_reshape = img.reshape()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check the shape\n", "img_reshape.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# after clustering, we will restore the original shape\n", "# the code below demonstrates that the original image is restored by reshaping\n", "# to the original dimensions \n", "\n", "fig, ax = plt.subplots(figsize=(10,10))\n", "img = mpimg.imread('./data/miro.jpg')\n", "restored_image = img_reshape.reshape(img.shape[0],img.shape[1], 3)\n", "imgplot = ax.imshow(restored_image)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# In pairs: 10 minute exercise"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, in pairs, we will use the KMeans algorithm to reduce the number of colors in the photo.   \n", "\n", "Start by reducing the number of colors to 2.  To do so we will have to pass an appropriate argument  when instantianting a KMeans object.  The number of clusters we initiate will determine the number of colors that the image is reduced to.\n", "\n", "In order to visualize the groupings, we will replace the original pixel values with the cluster centers associated with the assigned label."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Reminder of our flattened image\n", "img_reshape.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instantiate a KMeans object with the argument n_clusters equal to 2\n", "# code here\n", "km = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit the km object to img_reshape\n", "# code here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# view the assigned labels via the labels_ attribute\n", "# code here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# view the cluster centers via the cluster_centers_ attribute\n", "# code here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# create a list which stores the cluster center associated with each label in a list.  \n", "# The list should be 1734000 elements long\n", "\n", "label_centers = []\n", "for label in km.labels_:\n", "    None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Convert list to array\n", "centers_2 = np.array(label_centers)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# check shape is (1734000, 3)\n", "centers_2.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# reshape to (1200, 1445, 3)\n", "new_image_2 = None\n", "new_image_2.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run the cell below to plot the new image.  It should have only 2 colors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10,10))\n", "imgplot = ax.imshow(new_image_2.astype(int))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Explain in your own words why the image looks like it does."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, try out different numbers of clusters and see their affect on the painting."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}